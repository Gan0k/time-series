{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import crbm as C\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Global_active_power      float64\n",
       "Global_reactive_power    float64\n",
       "Voltage                  float64\n",
       "Global_intensity         float64\n",
       "Sub_metering_1           float64\n",
       "Sub_metering_2           float64\n",
       "Sub_metering_3           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allData = pd.read_csv('../household_power_consumption.txt',';',index_col=0,na_values='?',header=0,parse_dates=[[0, 1]],infer_datetime_format=True)\n",
    "\n",
    "allData.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reduce the number of data coputing the max of each hour\n",
    "groupedByH = allData.groupby(pd.TimeGrouper('H')).max()\n",
    "#groupedByH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split the dataset in traininig,validation and test set\n",
    "def splitDataset(dt):\n",
    "    y = dt.year\n",
    "    if(y>=2006 and y<=2008):\n",
    "        return 'training'\n",
    "    if(y==2009):\n",
    "        return 'validation'\n",
    "    if(y==2010):\n",
    "        return 'test'\n",
    "\n",
    "#remove the null rows\n",
    "def removeNullRows(dataSet):\n",
    "    idxNAN = pd.isnull(dataSet).any(1).nonzero()[0]\n",
    "\n",
    "#since there are the Nan, we should remove it before the training\n",
    "#therefore, we split the traiing set as sequnces of series without Nan\n",
    "    start = 0\n",
    "    idxSequences = []\n",
    "    seqlen = []\n",
    "    for idx in idxNAN:\n",
    "        if(start < idx):\n",
    "            #print str(start) + '-' + str(idx-1)\n",
    "            idxSequences += range(start,idx)\n",
    "            seqlen += [idx-start]\n",
    "            start = idx+1\n",
    "        else:\n",
    "            start = start +1\n",
    "    #print str(start) + '-' + str(len(dataSet))\n",
    "    idxSequences += range(start,len(dataSet))\n",
    "    seqlen +=  [len(dataSet)-start]\n",
    "    #print idxSequences\n",
    "    return dataSet.iloc[idxSequences],seqlen\n",
    "\n",
    "#normalize the values\n",
    "def normalizeValues(dataSet):\n",
    "    return (dataSet - dataSet.mean())/ dataSet.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splittedDataset = groupedByH.groupby(splitDataset)\n",
    "\n",
    "#split dataset\n",
    "trainingSet = splittedDataset.get_group('training')\n",
    "validationSet = splittedDataset.get_group('validation')\n",
    "testSet = splittedDataset.get_group('test')\n",
    "\n",
    "#remove null values\n",
    "trainingSet,seqlenTR = removeNullRows(trainingSet)\n",
    "validationSet,seqlenVAL = removeNullRows(validationSet)\n",
    "testSet,seqlenTE = removeNullRows(testSet)\n",
    "\n",
    "#normaliza all values with 0 mean and 1 std. dev.\n",
    "trainingSet = normalizeValues(trainingSet)\n",
    "validationSet = normalizeValues(validationSet)\n",
    "testSet = normalizeValues(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build batch data for the training\n",
    "batchdata = trainingSet.values\n",
    "\n",
    "#day and month of the batchdata\n",
    "idx_train = trainingSet.index\n",
    "dow = idx_train.dayofweek\n",
    "m = idx_train.month\n",
    "h = idx_train.hour\n",
    "d = idx_train.dayofyear\n",
    "\n",
    "season_year = np.cos(((24 * (d-1) + h)*2*np.pi/(365*24-1))+3*np.pi/2)\n",
    "season_week = np.cos((dow-1)*2*np.pi/6)\n",
    "season_day = np.cos(h*2*np.pi/23)\n",
    "\n",
    "#now create a matrix s.t. the column are seasonYear | seasonWeek | seasonDay | allOtherData\n",
    "batchdata = np.column_stack((season_day,batchdata))\n",
    "batchdata = np.column_stack((season_week,batchdata))\n",
    "batchdata = np.column_stack((season_year,batchdata))\n",
    "\n",
    "batchdata = np.asmatrix(batchdata)\n",
    "batchdata = theano.shared(np.asarray(batchdata, dtype=theano.config.floatX))\n",
    "\n",
    "# compute number of visible units\n",
    "n_dim = batchdata.get_value(borrow=True).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build validation set\n",
    "\n",
    "validationSet_matrix = validationSet.values\n",
    "\n",
    "#add seasonality\n",
    "idx_val = validationSet.index\n",
    "dow = idx_val.dayofweek\n",
    "m = idx_val.month\n",
    "h = idx_val.hour\n",
    "d = idx_val.dayofyear\n",
    "\n",
    "season_year = np.cos(((24 * (d-1) + h)*2*np.pi/(365*24-1))+3*np.pi/2)\n",
    "season_week = np.cos((dow-1)*2*np.pi/6)\n",
    "season_day = np.cos(h*2*np.pi/23)\n",
    "\n",
    "#now create a matrix s.t. the column are seasonYear | seasonWeek | seasonDay | allOtherData\n",
    "validationSet_matrix = np.column_stack((season_day,validationSet_matrix))\n",
    "validationSet_matrix = np.column_stack((season_week,validationSet_matrix))\n",
    "validationSet_matrix = np.column_stack((season_year,validationSet_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_training(n_hidden = 5, delay=3):\n",
    "\n",
    "    print '\\nN_HIDDEN='+str(n_hidden)+' DELAY='+str(delay) \n",
    "    #learning rate\n",
    "    learning_rate = 0.001;\n",
    "\n",
    "    #the size of the trainining epoch\n",
    "    batch_size = 24;\n",
    "\n",
    "    #number of training epochs\n",
    "    training_epochs=200;\n",
    "\n",
    "    # allocate symbolic variables for the data\n",
    "    index = T.lvector()    # index to a [mini]batch\n",
    "    index_hist = T.lvector()  # index to history\n",
    "    x = T.matrix('x')  # the data\n",
    "    x_history = T.matrix('x_history')\n",
    "\n",
    "    #theano.config.compute_test_value='warn'\n",
    "    #x.tag.test_value = np.random.randn(batch_size, n_dim)\n",
    "    #x_history.tag.test_value = np.random.randn(batch_size, n_dim*delay)\n",
    "\n",
    "    # initialize storage for the persistent chain\n",
    "    # (state = hidden layer of chain)\n",
    "\n",
    "    # construct the CRBM class\n",
    "    crbm = C.CRBM(input=x, input_history=x_history, n_visible=n_dim, n_hidden=n_hidden, delay=delay)\n",
    "\n",
    "    # get the cost and the gradient corresponding to one step of CD-15\n",
    "    cost, updates = crbm.get_cost_updates(lr=learning_rate, k=1)\n",
    "\n",
    "    batchdataindex = []\n",
    "    last = 0\n",
    "    for s in seqlenTR:\n",
    "        batchdataindex += range(last + delay, last + s)\n",
    "        last += s\n",
    "    permindex = np.array(batchdataindex)\n",
    "    n_train_batches = len(permindex)/ batch_size\n",
    "\n",
    "    train_crbm = theano.function([index, index_hist], cost,\n",
    "               updates=updates,\n",
    "               givens={\n",
    "                        x: batchdata[index],\n",
    "                        x_history: batchdata[index_hist].reshape((batch_size, delay * n_dim))\n",
    "                      },\n",
    "               name='train_crbm')\n",
    "\n",
    "    plotting_time = 0.\n",
    "    start_time = time.clock()\n",
    "\n",
    "    # go through training epochs\n",
    "    for epoch in xrange(training_epochs):\n",
    "\n",
    "        # go through the training set\n",
    "        mean_cost = []\n",
    "        for batch_index in xrange(n_train_batches):\n",
    "            #print '\\n'\n",
    "            # indexing is slightly complicated\n",
    "            # build a linear index to the starting frames for this batch\n",
    "            # (i.e. time t) gives a batch_size length array for data\n",
    "            data_idx = permindex[batch_index * batch_size:(batch_index + 1)* batch_size]\n",
    "            #print batch_index\n",
    "            #print data_idx\n",
    "            # now build a linear index to the frames at each delay tap\n",
    "            # (i.e. time t-1 to t-delay)\n",
    "            # gives a batch_size x delay array of indices for history\n",
    "            hist_idx = np.array([data_idx - n for n in xrange(1, delay + 1)]).T\n",
    "            #print hist_idx\n",
    "            this_cost = train_crbm(data_idx, hist_idx.ravel())\n",
    "            #print batch_index, this_cost\n",
    "            mean_cost += [this_cost]\n",
    "\n",
    "        print '\\rTraining epoch %d, cost is ' % epoch, np.mean(mean_cost),\n",
    "\n",
    "    end_time = time.clock()\n",
    "\n",
    "    pretraining_time = (end_time - start_time)\n",
    "\n",
    "    print ('\\nTraining took %f minutes' % (pretraining_time / 60.))\n",
    "    \n",
    "    return crbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#validate on the whole validation set\n",
    "def my_validation(crbm):\n",
    "    n_samples=1\n",
    "    delay = crbm.delay\n",
    "    \n",
    "    data_idx = []\n",
    "    last = 0\n",
    "    for s in seqlenVAL:\n",
    "        data_idx += range(last + delay, last + s)\n",
    "        last += s\n",
    "\n",
    "    data_idx = np.asarray(data_idx)\n",
    "    orig_data = np.asarray(validationSet_matrix[data_idx],dtype=theano.config.floatX)\n",
    "\n",
    "\n",
    "    hist_idx = np.array([data_idx - n for n in xrange(1, crbm.delay + 1)]).T\n",
    "    hist_idx = hist_idx.ravel()\n",
    "\n",
    "    orig_history = np.asarray(validationSet_matrix[hist_idx].reshape((len(data_idx), crbm.delay * crbm.n_visible)),dtype=theano.config.floatX)\n",
    "\n",
    "    generated_series = crbm.generate(orig_data, orig_history, n_samples=n_samples,n_gibbs=30)\n",
    "\n",
    "    MSE=[None]*crbm.n_visible\n",
    "    SMAPE=[None]*crbm.n_visible\n",
    "    for i in range(crbm.n_visible):\n",
    "        plotGEN = generated_series[:,n_samples-1,i]\n",
    "        #plt.subplot(crbm.n_visible, 1, i+1)\n",
    "        #plt.plot(plotGEN)\n",
    "        #plt.plot(bd[start:end,i])  \n",
    "        MSE[i] = np.sum(np.power(plotGEN - orig_data[:,i],2))/(len(orig_data))\n",
    "        SMAPE[i] = np.sum(np.abs(plotGEN - orig_data[:,i]) / (np.abs(plotGEN) + np.abs(orig_data[:,i]))) / len(orig_data) *100                                                                                               \n",
    "    return MSE,SMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "N_HIDDEN=3 DELAY=1\n",
      "Training epoch 199, cost is  3.6694582108 \n",
      "Training took 2.122001 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=3 DELAY=2\n",
      "Training epoch 199, cost is  3.33951425762 \n",
      "Training took 2.070955 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=3 DELAY=3\n",
      "Training epoch 199, cost is  3.32537270082 \n",
      "Training took 2.105050 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=3 DELAY=4\n",
      "Training epoch 199, cost is  3.30644145663 \n",
      "Training took 2.115609 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=3 DELAY=5\n",
      "Training epoch 199, cost is  3.01180724315 \n",
      "Training took 2.154035 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=5 DELAY=1\n",
      "Training epoch 199, cost is  3.59389780973 \n",
      "Training took 2.104648 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=5 DELAY=2\n",
      "Training epoch 199, cost is  3.38363568755 \n",
      "Training took 2.193111 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=5 DELAY=3\n",
      "Training epoch 199, cost is  3.24341882943 \n",
      "Training took 2.263880 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=5 DELAY=4\n",
      "Training epoch 199, cost is  3.03703211904 \n",
      "Training took 2.297712 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=5 DELAY=5\n",
      "Training epoch 199, cost is  3.08319710785 \n",
      "Training took 2.311368 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=7 DELAY=1\n",
      "Training epoch 199, cost is  3.66739479126 \n",
      "Training took 2.305972 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=7 DELAY=2\n",
      "Training epoch 199, cost is  3.5048696754 \n",
      "Training took 2.296394 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=7 DELAY=3\n",
      "Training epoch 199, cost is  3.49013216501 \n",
      "Training took 2.307972 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=7 DELAY=4\n",
      "Training epoch 199, cost is  3.37872065616 \n",
      "Training took 2.337034 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=7 DELAY=5\n",
      "Training epoch 199, cost is  3.43946126649 \n",
      "Training took 2.301393 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=10 DELAY=1\n",
      "Training epoch 199, cost is  3.79522349193 \n",
      "Training took 2.278265 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=10 DELAY=2\n",
      "Training epoch 199, cost is  3.67482119744 \n",
      "Training took 2.275169 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=10 DELAY=3\n",
      "Training epoch 199, cost is  3.56511022262 \n",
      "Training took 2.332706 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=10 DELAY=4\n",
      "Training epoch 199, cost is  3.54369607055 \n",
      "Training took 2.336868 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=10 DELAY=5\n",
      "Training epoch 199, cost is  3.5181298351 \n",
      "Training took 2.378879 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=20 DELAY=1\n",
      "Training epoch 199, cost is  4.07124211672 \n",
      "Training took 2.511360 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=20 DELAY=2\n",
      "Training epoch 199, cost is  3.97268261071 \n",
      "Training took 2.562473 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=20 DELAY=3\n",
      "Training epoch 199, cost is  3.862334832 \n",
      "Training took 2.563070 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=20 DELAY=4\n",
      "Training epoch 199, cost is  3.75980418651 \n",
      "Training took 2.482400 minutes\n",
      "Generating frame 0\n",
      "\n",
      "N_HIDDEN=20 DELAY=5\n",
      "Training epoch 199, cost is  3.82346642076 \n",
      "Training took 2.428966 minutes\n",
      "Generating frame 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "crbm.py:316: UserWarning: Updating an `OrderedUpdates` with a non-ordered dictionary with 2+ elements could make your code non-deterministic\n",
      "  ), axis=1)})\n"
     ]
    }
   ],
   "source": [
    "n_hidden_values = [3,5,7,10,20]\n",
    "delay_values = [1,2,3,4,5]\n",
    "\n",
    "#in the computation we should ignore the value about seasonlaity, i.e. the first 3\n",
    "store_MSE = np.zeros((len(n_hidden_values),len(delay_values),n_dim-3))\n",
    "store_SMAPE = np.zeros_like(store_MSE)\n",
    "\n",
    "for idx_nh in range(len(n_hidden_values)):\n",
    "    nh = n_hidden_values[idx_nh]\n",
    "    for idx_d in range(len(delay_values)):\n",
    "        d = delay_values[idx_d]\n",
    "        crbmMdl = my_training(n_hidden=nh,delay=d)\n",
    "        MSE,SMAPE = my_validation(crbm=crbmMdl)\n",
    "        store_MSE[idx_nh,idx_d,:] = MSE[3:]\n",
    "        store_SMAPE[idx_nh,idx_d,:] = SMAPE[3:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST N HIDDEN = 3\n",
      "BEST DELAY = 4\n",
      "BEST MSE = 0.980655235337\n"
     ]
    }
   ],
   "source": [
    "best_idx_nh,best_idx_d = np.unravel_index(store_MSE.mean(axis=2).argmin(),(len(n_hidden_values),len(delay_values)))\n",
    "best_d = delay_values[best_idx_d]\n",
    "best_nh = n_hidden_values[best_idx_nh]\n",
    "print 'BEST N HIDDEN = '+str(best_nh)\n",
    "print 'BEST DELAY = '+str(best_d)\n",
    "print 'BEST MSE = '+str(store_MSE[best_idx_nh,best_idx_d,:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST N HIDDEN = 3\n",
      "BEST DELAY = 5\n",
      "BEST SMAPE = 53.7702167135\n"
     ]
    }
   ],
   "source": [
    "best_idx_nh,best_idx_d = np.unravel_index(store_SMAPE.mean(axis=2).argmin(),(len(n_hidden_values),len(delay_values)))\n",
    "best_d = delay_values[best_idx_d]\n",
    "best_nh = n_hidden_values[best_idx_nh]\n",
    "print 'BEST N HIDDEN = '+str(best_nh)\n",
    "print 'BEST DELAY = '+str(best_d)\n",
    "print 'BEST SMAPE = '+str(store_SMAPE[best_idx_nh,best_idx_d,:].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
